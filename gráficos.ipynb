{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejorando la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se crean las derivadas y funciones de activación para usar en la red neuronal\n",
    "from sympy import *\n",
    "\n",
    "# Derivadas de las funciones de activación\n",
    "d_relu = lambda x: x > 0\n",
    "d_logistic = lambda x: np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "\n",
    "# Esto se hace para poder visualizar las derivadas sin asignar valores reales a las variables a derivar\n",
    "W1, W2, B1, B2, A1, A2, Z1, Z2, X, Y = symbols('W1 W2 B1 B2 A1 A2 Z1 Z2 X Y')\n",
    "\n",
    "# Derivada de la función costo respecto a A2\n",
    "C = (A2 - Y)**2\n",
    "dC_dA2 = diff(C, A2)    # Lo que hace diff es derivar el primer símbolo respecto al segundo\n",
    "print(\"dC_dA2 = \", dC_dA2) # 2*A2 - 2*Y\n",
    "\n",
    "# Derivada de A2 respecto de Z2\n",
    "logistic = lambda x: 1 / (1 + exp(-x))\n",
    "_A2 = logistic(Z2)\n",
    "dA2_dZ2 = diff(_A2, Z2)\n",
    "print(\"dA2_dZ2 = \", dA2_dZ2) # exp(-Z2)/(1 + exp(-Z2))**2\n",
    "\n",
    "# Derivada de Z2 respecto a A1\n",
    "_Z2 = A1*W2 + B2\n",
    "dZ2_dA1 = diff(_Z2, A1)\n",
    "print(\"dZ2_dA1 = \", dZ2_dA1) # W2\n",
    "\n",
    "# Derivada de Z2 respecto a W2\n",
    "dZ2_dW2 = diff(_Z2, W2)\n",
    "print(\"dZ2_dW2 = \", dZ2_dW2) # A1\n",
    "\n",
    "# Derivada de Z2 respecto a B2\n",
    "dZ2_dB2 = diff(_Z2, B2)\n",
    "print(\"dZ2_dB2 = \", dZ2_dB2) # 1\n",
    "\n",
    "# Derivada de A1 respecto de Z1\n",
    "relu = lambda x: Max(x, 0)\n",
    "_A1 = relu(Z1)\n",
    "\n",
    "d_relu = lambda x: x > 0 # Pendiente es 1 para los positivos, 0 para los negativos\n",
    "dA1_dZ1 = d_relu(Z1)\n",
    "print(\"dA1_dZ1 = \", dA1_dZ1) # Z1 > 0\n",
    "\n",
    "# Derivada de Z1 respecto a W1\n",
    "_Z1 = X*W1 + B1\n",
    "dZ1_dW1 = diff(_Z1, W1)\n",
    "print(\"dZ1_dW1 = \", dZ1_dW1) # X\n",
    "\n",
    "# Derivada de Z1 respecto a B1\n",
    "dZ1_dB1 = diff(_Z1, B1)\n",
    "print(\"dZ1_dB1 = \", dZ1_dB1) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se van a fijar valores para poder optimizar valores de L y rango. Luego, se van a graficar para ver cuáles son los más convenientes.\n",
    "\n",
    "dataframe = pd.read_csv(\"students.csv\")\n",
    "dataframe.drop(columns = [\"StudentID\", \"Age\", \"Gender\", \"Volunteering\", \"GradeClass\"], inplace = True)\n",
    "\n",
    "dataframe.loc[dataframe['GPA'] <= 2, 'GPA'] = 1\n",
    "dataframe.loc[dataframe['GPA'] > 2, 'GPA'] = 0\n",
    "\n",
    "def iniciar_pesos():\n",
    "    global w_hidden, b_hidden, w_output, b_output \n",
    "    np.random.seed(0) # Importante: Inicializamos la semilla en 0 para que siempre dé los mismos valores random.\n",
    "    w_hidden = np.random.rand(9, 9) * 2 - 1\n",
    "    w_output = np.random.rand(1, 9) * 2 - 1\n",
    "\n",
    "    b_hidden = np.random.rand(9, 1) * 2 - 1\n",
    "    b_output = np.random.rand(1, 1) * 2 - 1\n",
    "\n",
    "\n",
    "# Se extrae las columnas de entrada\n",
    "all_inputs = (dataframe.iloc[:, 0:9].values)\n",
    "# Se extrae la columna de salida\n",
    "all_outputs = dataframe.iloc[:, -1].values\n",
    "\n",
    "# Se divide en un conjunto de entrenamiento y uno de prueba (un tercio para el testeo)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(all_inputs, all_outputs, test_size=1/3)\n",
    "\n",
    "n = X_train.shape[0] # número de registros de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para graficar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar los gráficos\n",
    "fmt_train = {\n",
    "    'color': 'tab:blue',\n",
    "    'ls': 'solid',\n",
    "    'lw': 3,\n",
    "}\n",
    "\n",
    "fmt_test = {\n",
    "    'color': 'tab:orange',\n",
    "    'ls': 'solid',\n",
    "    'lw': 3,\n",
    "}\n",
    "\n",
    "# Graficar accuracy de cada combinación\n",
    "def graficar_accuracy(L, train, test):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    ax.plot(train, label=\"Train\", **fmt_train)\n",
    "    ax.plot(test, label=\"Test\", **fmt_test)\n",
    "\n",
    "\n",
    "    ax.grid(which=\"both\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{L=}\")\n",
    "    ax.set_xlabel(\"Iteraciones\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Además, a la hora de ir entrenando la red tendremos que ir guardando información para realizar los gráficos.\n",
    "def entrenarProbarGuardar(L, rango):\n",
    "  global w_hidden, b_hidden, w_output, b_output  \n",
    "  iniciar_pesos() # Para que no aprenda sobre lo aprendido\n",
    "\n",
    "  accuracy_TEST_l = []  # Se vacían para graficar cada combinación\n",
    "  accuracy_TRAIN_l = []\n",
    "\n",
    "  for i in tqdm(range(rango)):\n",
    "    # seleccionar aleatoriamente uno de los datos de entrenamiento\n",
    "    idx = np.random.choice(n, 1, replace=False)\n",
    "    X_sample = X_train[idx].transpose()\n",
    "    Y_sample = Y_train[idx]\n",
    "\n",
    "    # pasar datos seleccionados aleatoriamente a través de la red neuronal\n",
    "    Z1, A1, Z2, A2 = forward_prop(X_sample)\n",
    "\n",
    "    # distribuir error a través de la retropropagación\n",
    "    # y devolver pendientes para pesos y sesgos\n",
    "    dW1, dB1, dW2, dB2 = backward_prop(Z1, A1, Z2, A2, X_sample, Y_sample)\n",
    "\n",
    "    # actualizar pesos y sesgos\n",
    "    w_hidden -= L * dW1\n",
    "    b_hidden -= L * dB1\n",
    "    w_output -= L * dW2\n",
    "    b_output -= L * dB2\n",
    "\n",
    "    # Calculamos de precisión de TEST\n",
    "    predictions = forward_prop(X_test.transpose())[3] # Capa de salida A2\n",
    "    test_comparisons = np.equal((predictions > 0.5).flatten().round(), Y_test) # Cambiará en algo el =>\n",
    "    accuracy_TEST = sum(test_comparisons.astype(int) / X_test.shape[0])\n",
    "    accuracy_TEST_l.append(accuracy_TEST)\n",
    "\n",
    "    # Calculamos presición de TRAIN\n",
    "    predictions = forward_prop(X_train.transpose())[3] # Capa de salida A2\n",
    "    train_comparisons = np.equal((predictions > 0.5).flatten().round(), Y_train)\n",
    "    accuracy_TRAIN = sum(train_comparisons.astype(int) / X_train.shape[0])\n",
    "    accuracy_TRAIN_l.append(accuracy_TRAIN)\n",
    "    \n",
    "  # Se grafica y compara la precisión de TEST y TRAIN\n",
    "  graficar_accuracy(L,  accuracy_TRAIN_l, accuracy_TEST_l)\n",
    "  \n",
    "# Lista de L a probar\n",
    "l_probados = [0.0005, 0.005, 0.0001, 0.001, 0.05, 0.01, 0.1]\n",
    "# Lista de ranges a probar\n",
    "range_probados = [1_000, 3_000, 5_000, 10_000, 20_000, 30_000, 50_000, 100_000]\n",
    "\n",
    "# Probar cada combinación de L e iteraciones\n",
    "for L in l_probados:\n",
    "    for rango in range_probados:           \n",
    "         entrenarProbarGuardar(L, rango)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # Ojos que no ven, corazón que no siente\n",
    "\n",
    "# Cargar y preparar datos\n",
    "dataframe_ = pd.read_csv(\"students.csv\")\n",
    "dataframe_.drop(columns=[\"StudentID\", \"Age\", \"Gender\", \"Volunteering\", \"GradeClass\"], inplace=True)\n",
    "df = dataframe_\n",
    "np.random.seed(0)\n",
    "df['GoodStudent'] = (df.iloc[:, -1] >= 2).astype(int)\n",
    "X = df.values[:, :-1]\n",
    "Y = df['GoodStudent'].values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/3, random_state=42)\n",
    "\n",
    "def graficar_red_scikit(L, rango):\n",
    "    \n",
    "    # Crear el modelo de red neuronal con warm_start\n",
    "    red_neuronal = MLPClassifier(\n",
    "        solver='sgd', hidden_layer_sizes=(9,), activation='relu',\n",
    "        max_iter=1, learning_rate_init=L, warm_start=True, random_state=0)\n",
    "\n",
    "    # Listas para almacenar las precisiones en cada iteración\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    # Entrenamiento iterativo para registrar precisión en cada ciclo\n",
    "    for i in range(rango):\n",
    "        red_neuronal.fit(X_train, Y_train)\n",
    "        train_accuracy.append(red_neuronal.score(X_train, Y_train))\n",
    "        test_accuracy.append(red_neuronal.score(X_test, Y_test))\n",
    "\n",
    "    # Graficar precisión por iteración\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(train_accuracy, label=\"Train\", **fmt_train)\n",
    "    plt.plot(test_accuracy, label=\"Test\", **fmt_test)\n",
    "    plt.xlabel(\"Iteraciones\")\n",
    "    plt.ylabel(\"Precisión\")\n",
    "    plt.title(f\"{L=}\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de L a probar\n",
    "l_probados = [0.0005, 0.005, 0.0001, 0.001, 0.05, 0.01, 0.1]\n",
    "# Lista de ranges a probar\n",
    "range_probados = [1_000, 3_000, 5_000, 10_000, 20_000, 30_000, 50_000, 100_000]\n",
    "\n",
    "# Probar cada combinación de L e iteraciones\n",
    "for L in l_probados:\n",
    "    for rango in range_probados:   \n",
    "        graficar_red_scikit(L, rango)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
